{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus= tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input, Conv2D, MaxPooling2D, UpSampling2D \n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 28, 28, 1) / 255\n",
    "x_test = x_test.reshape(10000, 28, 28, 1) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x141bd207040>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "noise_factor = 0.5\n",
    "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \n",
    "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \n",
    "\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
    "\n",
    "#Print one image to see the noise\n",
    "plt.imshow(x_test_noisy[1].reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(28, 28, 1))\n",
    "\n",
    "nn = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "nn = MaxPooling2D((2, 2), padding='same')(nn)\n",
    "nn = Conv2D(32, (3, 3), activation='relu', padding='same')(nn)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
    "nn = UpSampling2D((2, 2))(nn)\n",
    "nn = Conv2D(32, (3, 3), activation='relu', padding='same')(nn)\n",
    "nn = UpSampling2D((2, 2))(nn)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 0.2147 - val_loss: 0.2136 ETA: 2s - los\n",
      "Epoch 2/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.2131 - val_loss: 0.2119\n",
      "Epoch 3/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.2114 - val_loss: 0.2102s: 0.21 - ETA: 2s - ETA:\n",
      "Epoch 4/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.2098 - val_loss: 0.2086oss: 0. - ETA: 2 - ETA: 1s - los - ETA: 0s - loss: 0.21 - ETA: 0s - loss:\n",
      "Epoch 5/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.2082 - val_loss: 0.2070\n",
      "Epoch 6/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.2066 - val_loss: 0.2054\n",
      "Epoch 7/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.2051 - val_loss: 0.2039 1s - loss: 0.2 -  - ETA: 0s - loss: 0.205\n",
      "Epoch 8/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.2036 - val_loss: 0.20242s - lo - ETA: 2s - loss: 0. - ETA: 1s - loss:  - ETA: 1s - - ETA: 0s - loss:  - ETA: 0s - loss: 0.203 - ETA: 0s - loss: 0.2\n",
      "Epoch 9/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.2021 - val_loss: 0.2009A: 0s - los - ETA: 0s - loss: 0.202\n",
      "Epoch 10/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.2008 - val_loss: 0.1996\n",
      "Epoch 11/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1994 - val_loss: 0.1982\n",
      "Epoch 12/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1981 - val_loss: 0.1969TA: 0s\n",
      "Epoch 13/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1968 - val_loss: 0.1956A: 2s - loss: 0.19 - ETA: 0s - loss: 0.1 - ETA: 0s - loss: 0.\n",
      "Epoch 14/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1956 - val_loss: 0.1944 \n",
      "Epoch 15/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1944 - val_loss: 0.1932ETA: 1s - loss: 0.1 - \n",
      "Epoch 16/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1933 - val_loss: 0.1921\n",
      "Epoch 17/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1922 - val_loss: 0.1910 - ETA: 1s - ETA: 0s - l\n",
      "Epoch 18/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1911 - val_loss: 0.1900\n",
      "Epoch 19/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1901 - val_loss: 0.1889A: 0s - los - ETA: 0s - loss: 0.190\n",
      "Epoch 20/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1892 - val_loss: 0.1880\n",
      "Epoch 21/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1882 - val_loss: 0.1870 l\n",
      "Epoch 22/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1873 - val_loss: 0.1861TA: 2s - loss: 0.187 - ET\n",
      "Epoch 23/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1864 - val_loss: 0.1852\n",
      "Epoch 24/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1856 - val_loss: 0.1844\n",
      "Epoch 25/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1848 - val_loss: 0.1836- los - ETA: 1 - ETA: 0s\n",
      "Epoch 26/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1840 - val_loss: 0.1828\n",
      "Epoch 27/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1832 - val_loss: 0.1820ss:  - ETA: 0s - loss:  - ETA: 0s - loss\n",
      "Epoch 28/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1825 - val_loss: 0.1813 l - ETA: 0s - loss\n",
      "Epoch 29/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1818 - val_loss: 0.1806 0. - ETA: 0s - loss: 0.\n",
      "Epoch 30/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1811 - val_loss: 0.1799loss: 0.181\n",
      "Epoch 31/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1804 - val_loss: 0.1792\n",
      "Epoch 32/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1798 - val_loss: 0.1786ETA: 0s - los\n",
      "Epoch 33/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1792 - val_loss: 0.1780\n",
      "Epoch 34/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1786 - val_loss: 0.1774\n",
      "Epoch 35/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1780 - val_loss: 0.1768\n",
      "Epoch 36/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1774 - val_loss: 0.1762- ETA: 3s - loss - ETA: 2 - E - ETA: 0s - loss\n",
      "Epoch 37/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1768 - val_loss: 0.1756loss: 0.\n",
      "Epoch 38/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1763 - val_loss: 0.1751\n",
      "Epoch 39/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1758 - val_loss: 0.1746  - E - ETA: 0s - loss: 0\n",
      "Epoch 40/200\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 0.1753 - val_loss: 0.1740\n",
      "Epoch 41/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1748 - val_loss: 0.1735TA: 1s - loss: 0.1 \n",
      "Epoch 42/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1743 - val_loss: 0.1730\n",
      "Epoch 43/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1738 - val_loss: 0.1726\n",
      "Epoch 44/200\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 0.1733 - val_loss: 0.1721\n",
      "Epoch 45/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1729 - val_loss: 0.1716\n",
      "Epoch 46/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1724 - val_loss: 0.1712\n",
      "Epoch 47/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1720 - val_loss: 0.1708A: 2s - loss: 0.1 - ETA: 1s - ETA: 0s - - ETA: 0s - loss: 0.1\n",
      "Epoch 48/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1716 - val_loss: 0.1703s - loss: 0. - ETA: 0s - loss: \n",
      "Epoch 49/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1711 - val_loss: 0.1699\n",
      "Epoch 50/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1707 - val_loss: 0.1695\n",
      "Epoch 51/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1703 - val_loss: 0.1691\n",
      "Epoch 52/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1699 - val_loss: 0.1687 ETA: 2s - los - ETA: 2s - loss: 0 - ETA: 1s - loss - ETA: 1s -  - ETA: 0s - l\n",
      "Epoch 53/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1696 - val_loss: 0.1683: 0.16\n",
      "Epoch 54/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1692 - val_loss: 0.1679s: 0.1\n",
      "Epoch 55/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1688 - val_loss: 0.1676ET\n",
      "Epoch 56/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1684 - val_loss: 0.1672 - ETA: 0s - loss: 0.\n",
      "Epoch 57/200\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 0.1681 - val_loss: 0.1668\n",
      "Epoch 58/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1677 - val_loss: 0.1665: 2s - loss: 0.1 - E - ETA: 0s - \n",
      "Epoch 59/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1674 - val_loss: 0.1661o\n",
      "Epoch 60/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1670 - val_loss: 0.1658\n",
      "Epoch 61/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1667 - val_loss: 0.1654\n",
      "Epoch 62/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1663 - val_loss: 0.1651A: 0s - loss:  - ETA: 0s - loss: 0.1 - ETA: 0s - loss: \n",
      "Epoch 63/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1660 - val_loss: 0.1648\n",
      "Epoch 64/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1657 - val_loss: 0.1644\n",
      "Epoch 65/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1654 - val_loss: 0.1641\n",
      "Epoch 66/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1650 - val_loss: 0.1638\n",
      "Epoch 67/200\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 0.1647 - val_loss: 0.1635s: 0. - ETA: 1s - loss: 0 - ETA: 0s \n",
      "Epoch 68/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1644 - val_loss: 0.1632\n",
      "Epoch 69/200\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 0.1641 - val_loss: 0.1629\n",
      "Epoch 70/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1638 - val_loss: 0.1626\n",
      "Epoch 71/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1635 - val_loss: 0.1623\n",
      "Epoch 72/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1632 - val_loss: 0.162016 - ETA: 2s - loss: 0.1 - ETA: 1s - loss: 0\n",
      "Epoch 73/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1629 - val_loss: 0.1617 1s - loss: 0 - ETA: 1s - loss - ETA: 0s - loss: 0.1 - ETA: 0s - los\n",
      "Epoch 74/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1626 - val_loss: 0.1614- ETA: 0s - loss: 0.162 - ETA: 0s - loss: 0.162\n",
      "Epoch 75/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1623 - val_loss: 0.1611\n",
      "Epoch 76/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1621 - val_loss: 0.1608\n",
      "Epoch 77/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1618 - val_loss: 0.1605\n",
      "Epoch 78/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1615 - val_loss: 0.16022s - los - ETA: 2s - loss: 0 - ETA: 2s - los\n",
      "Epoch 79/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1612 - val_loss: 0.1600A: 3s - lo - ETA: 2s - loss: 0.1 - ET - ETA:\n",
      "Epoch 80/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1610 - val_loss: 0.1597\n",
      "Epoch 81/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1607 - val_loss: 0.1594s: 0.160\n",
      "Epoch 82/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1604 - val_loss: 0.1592\n",
      "Epoch 83/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1602 - val_loss: 0.1589\n",
      "Epoch 84/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1599 - val_loss: 0.1587E\n",
      "Epoch 85/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1597 - val_loss: 0.1584 1s - loss: 0 - ETA: 1s - loss: - ETA: 1s - loss:  - ETA: 0s - loss: - ETA: 0s - loss: 0.1 - ETA: 0s - loss: 0.15\n",
      "Epoch 86/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1594 - val_loss: 0.1582\n",
      "Epoch 87/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1592 - val_loss: 0.1579\n",
      "Epoch 88/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1590 - val_loss: 0.1577\n",
      "Epoch 89/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1587 - val_loss: 0.1574\n",
      "Epoch 90/200\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 0.1585 - val_loss: 0.1572 2s - loss: 0 - ETA: 1s - loss: - ET - ETA: 0s - loss: 0.158\n",
      "Epoch 91/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1582 - val_loss: 0.1570\n",
      "Epoch 92/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1580 - val_loss: 0.1567los\n",
      "Epoch 93/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1578 - val_loss: 0.1565\n",
      "Epoch 94/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1575 - val_loss: 0.1563o - ETA: 1s - loss: - ETA: 0s - loss: 0.157 - ETA: 0s - loss: 0.157 - ETA: 0s - \n",
      "Epoch 95/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1573 - val_loss: 0.1560 - ETA: 0s - loss: 0.1\n",
      "Epoch 96/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1571 - val_loss: 0.1558\n",
      "Epoch 97/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1569 - val_loss: 0.1556- ETA: 2s - - ETA - ETA: 0s - loss: 0.15 - ETA: 0s - loss: 0 - ETA: 0s - loss: 0.156\n",
      "Epoch 98/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1567 - val_loss: 0.1554\n",
      "Epoch 99/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1565 - val_loss: 0.1552\n",
      "Epoch 100/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1562 - val_loss: 0.1549\n",
      "Epoch 101/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1560 - val_loss: 0.1547\n",
      "Epoch 102/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1558 - val_loss: 0.1545A: \n",
      "Epoch 103/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1556 - val_loss: 0.1543\n",
      "Epoch 104/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1554 - val_loss: 0.1541A: 0s - lo\n",
      "Epoch 105/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1552 - val_loss: 0.1539 - ETA: 0s - loss:\n",
      "Epoch 106/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1550 - val_loss: 0.1537 lo - ETA: 0s -\n",
      "Epoch 107/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1548 - val_loss: 0.1535\n",
      "Epoch 108/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1546 - val_loss: 0.1533ETA: 2s - loss: 0. - ETA: 2s - loss - ETA: 2s - loss: - ETA: 1 - ETA: 0s - l\n",
      "Epoch 109/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1544 - val_loss: 0.1531s\n",
      "Epoch 110/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1542 - val_loss: 0.1529\n",
      "Epoch 111/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1540 - val_loss: 0.1527ETA - ETA: 2s - lo - ETA: 1s - loss: - ETA: \n",
      "Epoch 112/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1538 - val_loss: 0.1525\n",
      "Epoch 113/200\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 0.1536 - val_loss: 0.1523\n",
      "Epoch 114/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1535 - val_loss: 0.1521\n",
      "Epoch 115/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1533 - val_loss: 0.1520\n",
      "Epoch 116/200\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 0.1531 - val_loss: 0.1518\n",
      "Epoch 117/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1529 - val_loss: 0.1516\n",
      "Epoch 118/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1527 - val_loss: 0.1514\n",
      "Epoch 119/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1526 - val_loss: 0.1512 ETA: 0s - l - ETA: 0s - loss: 0.152\n",
      "Epoch 120/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1524 - val_loss: 0.1510\n",
      "Epoch 121/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1522 - val_loss: 0.1509\n",
      "Epoch 122/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1520 - val_loss: 0.1507\n",
      "Epoch 123/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1519 - val_loss: 0.15051s - los - \n",
      "Epoch 124/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1517 - val_loss: 0.1503oss: 0.151 - ETA: 0s - loss:\n",
      "Epoch 125/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1515 - val_loss: 0.1502ETA: 1s - lo - ETA:\n",
      "Epoch 126/200\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 0.1513 - val_loss: 0.1500 - ETA: 0s - loss: 0.\n",
      "Epoch 127/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1512 - val_loss: 0.1498\n",
      "Epoch 128/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1510 - val_loss: 0.1497\n",
      "Epoch 129/200\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 0.1508 - val_loss: 0.1495\n",
      "Epoch 130/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1507 - val_loss: 0.1493ETA: 2s - loss: 0 - ETA: 2 - ET\n",
      "Epoch 131/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1505 - val_loss: 0.1492A: 0s - loss: - ETA: 0s - loss: 0\n",
      "Epoch 132/200\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 0.1504 - val_loss: 0.14902s - los - ETA: 2s - l - ETA: 1 - ETA: 0s - loss: \n",
      "Epoch 133/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1502 - val_loss: 0.1488\n",
      "Epoch 134/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1500 - val_loss: 0.1487\n",
      "Epoch 135/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1499 - val_loss: 0.1485TA: 1s - loss: 0.150 - ETA - ETA: 0s - loss:\n",
      "Epoch 136/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1497 - val_loss: 0.1484\n",
      "Epoch 137/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1496 - val_loss: 0.1482\n",
      "Epoch 138/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1494 - val_loss: 0.1481\n",
      "Epoch 139/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1493 - val_loss: 0.1479- loss:  - ETA: 2s - l - ETA - ETA: 0s - loss: 0.\n",
      "Epoch 140/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1491 - val_loss: 0.1477\n",
      "Epoch 141/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1490 - val_loss: 0.1476\n",
      "Epoch 142/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1488 - val_loss: 0.1474\n",
      "Epoch 143/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1487 - val_loss: 0.1473 ETA: 0s - loss: 0.14\n",
      "Epoch 144/200\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 0.1485 - val_loss: 0.14710s - los\n",
      "Epoch 145/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1484 - val_loss: 0.14700.14 - ETA: 0s - loss: 0.\n",
      "Epoch 146/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1482 - val_loss: 0.1468\n",
      "Epoch 147/200\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 0.1481 - val_loss: 0.1467ETA: 0s - loss:\n",
      "Epoch 148/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1479 - val_loss: 0.1466\n",
      "Epoch 149/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1478 - val_loss: 0.1464TA: 1s - loss: 0.147 - ETA: 1s  - ETA: 0s - los\n",
      "Epoch 150/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1477 - val_loss: 0.1463\n",
      "Epoch 151/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1475 - val_loss: 0.1461\n",
      "Epoch 152/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1474 - val_loss: 0.1460ETA: 3s -  - ETA: 2s - loss - ETA: - ETA: 0s - loss: 0.1 - ETA: 0s - loss\n",
      "Epoch 153/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1472 - val_loss: 0.1458A: 1s - loss:  \n",
      "Epoch 154/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1471 - val_loss: 0.1457\n",
      "Epoch 155/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1470 - val_loss: 0.1456\n",
      "Epoch 156/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1468 - val_loss: 0.1454: 1s - los - ETA: 0s - los\n",
      "Epoch 157/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1467 - val_loss: 0.1453\n",
      "Epoch 158/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1465 - val_loss: 0.1452 2s - loss:  - ETA: 2s - loss: 0.146 - ETA: - ETA:\n",
      "Epoch 159/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1464 - val_loss: 0.1450 loss: 0.146 - ETA: 2s - lo  - ETA: 0s - loss: 0. - ETA: 0s - loss: 0.146\n",
      "Epoch 160/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1463 - val_loss: 0.1449\n",
      "Epoch 161/200\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 0.1462 - val_loss: 0.1448 ETA: 0s - loss: 0\n",
      "Epoch 162/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1460 - val_loss: 0.1446ETA: \n",
      "Epoch 163/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1459 - val_loss: 0.1445s: 0\n",
      "Epoch 164/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1458 - val_loss: 0.1444oss - ETA: 0s \n",
      "Epoch 165/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1456 - val_loss: 0.14422s - loss: - ETA: 0s - loss: 0.14\n",
      "Epoch 166/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1455 - val_loss: 0.1441 \n",
      "Epoch 167/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1454 - val_loss: 0.1440ETA: 0s - loss\n",
      "Epoch 168/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1452 - val_loss: 0.1438: 1s -  - ETA: 1s - loss: 0.145 - ETA: 0s\n",
      "Epoch 169/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1451 - val_loss: 0.1437: 0.14  - ETA: 0s - l\n",
      "Epoch 170/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1450 - val_loss: 0.1436- ETA: 2s  - ETA: 0s - loss:\n",
      "Epoch 171/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1449 - val_loss: 0.1434TA: 0s - loss\n",
      "Epoch 172/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1447 - val_loss: 0.1433- ETA:  - ETA: 2s -\n",
      "Epoch 173/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1446 - val_loss: 0.1432\n",
      "Epoch 174/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1445 - val_loss: 0.1431: 0s -\n",
      "Epoch 175/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1444 - val_loss: 0.1429: 1s - loss:\n",
      "Epoch 176/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1442 - val_loss: 0.1428os - ETA: 0s - loss: 0.144\n",
      "Epoch 177/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1441 - val_loss: 0.1427\n",
      "Epoch 178/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1440 - val_loss: 0.1426 ETA:  - ETA: 0s - lo\n",
      "Epoch 179/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1439 - val_loss: 0.1425\n",
      "Epoch 180/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1438 - val_loss: 0.1423 - los\n",
      "Epoch 181/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1436 - val_loss: 0.14223 - \n",
      "Epoch 182/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1435 - val_loss: 0.1421\n",
      "Epoch 183/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1434 - val_loss: 0.1420\n",
      "Epoch 184/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1433 - val_loss: 0.1418A: 2s - loss:  - ETA: 1s - lo - ETA: 1s - loss: 0. - ETA: 0s\n",
      "Epoch 185/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1432 - val_loss: 0.14170 - ETA: 0s - loss: 0\n",
      "Epoch 186/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1430 - val_loss: 0.1416 loss: 0.1\n",
      "Epoch 187/200\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 0.1429 - val_loss: 0.1415\n",
      "Epoch 188/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1428 - val_loss: 0.1414\n",
      "Epoch 189/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1427 - val_loss: 0.1412: 0s - loss\n",
      "Epoch 190/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1426 - val_loss: 0.14110s - \n",
      "Epoch 191/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1425 - val_loss: 0.1410\n",
      "Epoch 192/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1424 - val_loss: 0.1409\n",
      "Epoch 193/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1422 - val_loss: 0.1408: 0s -\n",
      "Epoch 194/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1421 - val_loss: 0.1407\n",
      "Epoch 195/200\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 0.1420 - val_loss: 0.1406ETA: 2s - loss: 0.14 - ETA: 2s - loss - ETA: 2s - loss: 0.1 - E - ETA: 0s - loss\n",
      "Epoch 196/200\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 0.1419 - val_loss: 0.1404 0\n",
      "Epoch 197/200\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 0.1418 - val_loss: 0.1403: 0s - los - ETA: 0s - loss: 0.14\n",
      "Epoch 198/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1417 - val_loss: 0.1402\n",
      "Epoch 199/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1416 - val_loss: 0.1401- ETA: 1s - loss: 0 - ETA: 1s - - ETA: 0s - loss:\n",
      "Epoch 200/200\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.1415 - val_loss: 0.1400ETA: 0s - loss: 0. - ETA: 0s - loss: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1418edf4a60>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta',loss='binary_crossentropy')\n",
    "autoencoder.fit(x_train_noisy, x_train,\n",
    "                epochs=200,\n",
    "                batch_size=256,\n",
    "                validation_data=(x_test_noisy, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = autoencoder.predict((x_test_noisy[1].reshape(1, 28, 28, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1427d93f190>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAARsElEQVR4nO3dW4yc5XkH8P9/9mh7fVpsL45twIA5uAmYaktoqBAVJCVELaAqVXwRUQnJuQApkbgoSi9CpV6gqkmUi4rKKShuRYgiEQRSEYS4NIS0INZgsMEFO+Bg48VrvD6s7T3OPL3Yz9Fi9n2+YU7fwPP/SdbuzjPfzMvs/vl25/ne96WZQUQ++0pFD0BEWkNhFwlCYRcJQmEXCUJhFwmis5VP1s0e6+Wi9B3UGBDJRyZLE3YaUzYx7x3qCjvJWwD8CEAHgH8zswe8+/dyEa7r/Itk3WZm6hmOSAjs6k7WXpx+Olmr+dd4kh0A/gXAVwFsBLCZ5MZaH09Emquev9mvBbDPzN4xsykAPwNwW2OGJSKNVk/Y1wA4MOfrg9ltH0FyC8khkkPTNlnH04lIPeoJ+3xvAnzsLTYz22pmg2Y22MWeOp5OROpRT9gPAlg35+u1AA7VNxwRaZZ6wv4ygA0k15PsBvANAE82Zlgi0mg1t97MbIbkPQCewWzr7WEze8M/SO01kXrZzLRTTF+sUlef3cyeAvBUPY8hIq2hy2VFglDYRYJQ2EWCUNhFglDYRYJQ2EWCaOl8dklw5icDADu7/ONL/vH+U9d+LADUszqxTedcc2GVvCev+bkj0pldJAiFXSQIhV0kCIVdJAiFXSQIhV0kCLXequW0qNjR4R/a46/Qwws/tprXR5y+eJlfH0g/P3O6V+Vev24dfmuuY8Jvf5Wc7trSfePusd0HR9165egxt25TU+nap7ntV+Nz68wuEoTCLhKEwi4ShMIuEoTCLhKEwi4ShMIuEoT67FXyeuml5cvdYysXDrj1/V9b4tanLz/j1pf0pfvV02X/GoDlC/1e94JOZ9liAB0lvx/d6dR37VvrHrt0p18//4XFbr1j+MNkrXzsuHtsfh++7NfbkM7sIkEo7CJBKOwiQSjsIkEo7CJBKOwiQSjsIkGoz35W3nLOzpz08vrz3WM/vKbPrff/6Qduff0Sf173BQvS9aWdfh99bbf/2Jd0jbj1paVJt97rTKjf9blV7rE/veI6t76n8wq3vvq/0zWOnXKPze2zfwrVFXaS+wGMASgDmDGzwUYMSkQarxFn9j83s/SlSiLSFvQ3u0gQ9YbdAPyS5A6SW+a7A8ktJIdIDk3D//tORJqn3l/jrzezQyRXAXiW5P+Z2fNz72BmWwFsBYAl7NfmXCIFqevMbmaHso8jAB4HcG0jBiUijVdz2EkuIrn47OcAvgJgd6MGJiKNVc+v8QMAHs+2/O0E8FMze7oho/qUKZ3x53z3HfLnPg+/6s93H6Ff/9/e9F9Htswf21XrD7r1W1ftcuuXdfvXCPR3pOfin6n46+lXzL/2oZReFn62PpZ+7sqU/7rkrhv/KVRz2M3sHQBXN3AsItJEar2JBKGwiwShsIsEobCLBKGwiwShKa5Vspn0lMfSB0fcY/vGTrv1iz/wt2Qu9/rfpsn+rmTt+KV+e+v3OctgH+tf5NbL3X57bMLSS1nvm/RbijvevcCtX/Kq/7racHp6rs3ktd4+exd76swuEoTCLhKEwi4ShMIuEoTCLhKEwi4ShMIuEoT67NUqp6epVnKWJeYZfznn0kn/+FJ3uo8OAJ0r+5O1qT6/h38mZxrpQNcJt76yw+91e94cW+3W+3YscOudb7/l1svjE+niZ7CPnkdndpEgFHaRIBR2kSAUdpEgFHaRIBR2kSAUdpEg1Gc/K6fv6s1n93rwwOweWa4Jf1usUq8/J53LliRrU0v8Pvqmgffd+kVd/p6do+WFbv1XY3+UrO159Er32LWPvePWZ0aPu3VU/O9LNDqziwShsIsEobCLBKGwiwShsIsEobCLBKGwiwShPnsj1D03Omd74Ipfnzkvvbb7iQ3+2G5e/qZbH+jw59o/c3qjW3/klS8ma1c+PeweWz7i9/jVR/9kcs/sJB8mOUJy95zb+kk+S3Jv9tHfaUBEClfNr/E/AXDLObfdB2C7mW0AsD37WkTaWG7Yzex5AKPn3HwbgG3Z59sA3N7gcYlIg9X6Bt2AmQ0DQPZxVeqOJLeQHCI5NA3/GnARaZ6mvxtvZlvNbNDMBrvgT+gQkeapNeyHSa4GgOxjertMEWkLtYb9SQB3Zp/fCeCJxgxHRJolt89O8lEANwJYQfIggO8BeADAz0neBeA9AF9v5iCjKy1b6tb335zus9/wpV3usVf0+L3uAzP+c//ohS+79cu3nknWyu+85x6rPnpj5YbdzDYnSjc1eCwi0kS6XFYkCIVdJAiFXSQIhV0kCIVdJAhNcW0D7PS3ZB7//Fq3ftNf7kjWtqz8tXtsf8lZIhvAm5Nr3PrA8x1unW+n22um1lpL6cwuEoTCLhKEwi4ShMIuEoTCLhKEwi4ShMIuEoT67G2gtH6dWz9y97hbv3fV9mStv8Pvg7821efW/+F//sqtX/nMXrdePuUvRf2pRX8r7Fx1Lz/+yenMLhKEwi4ShMIuEoTCLhKEwi4ShMIuEoTCLhKE+uwtUOrtdevvbh5w6w9e9a9ufX1XuldeNn+7510Tfo9/4L/8H5HKiTG3XkQ/uSHy+ujMOU/mvO5F0JldJAiFXSQIhV0kCIVdJAiFXSQIhV0kCIVdJAj12RuAPT1uvXzN5W79r+/4jVu/utufE162dB//aMWfC//Qvi+59fN3HPWfe2barbetnD46u7v9es46ATbtr8dv3uuWd22CN3bn0NwzO8mHSY6Q3D3ntvtJvk9yZ/bv1rzHEZFiVfNr/E8A3DLP7T80s03Zv6caOywRabTcsJvZ8wBGWzAWEWmiet6gu4fk69mv+ctTdyK5heQQyaFpTNbxdCJSj1rD/iCASwBsAjAM4PupO5rZVjMbNLPBLvhvZIlI89QUdjM7bGZlM6sA+DGAaxs7LBFptJrCTnL1nC/vALA7dV8RaQ+5fXaSjwK4EcAKkgcBfA/AjSQ3Ybartx/At5o4xvbg9DY7Pne+e+h7Ny9y6/+49BW33lfy//w5Zen3QvbP+P3isTf73fr5I2+59baer+58z0oLFviHLvbX08996vEJt14+5e1NnzMXPm8ufUJu2M1s8zw3P1TTs4lIYXS5rEgQCrtIEAq7SBAKu0gQCrtIEJriWiWvVXP0+tXJGgD0/ok/TfS8kn8Z8aT536bdU+nW3H+e2OQeu3i/W86Xt+RyPa25vGmonV1uvbRsabJWvsT/no0P+Mt/d4777bGeQ/605NK7B5I1m8y5rNxrvVWcdqP/qCLyWaGwiwShsIsEobCLBKGwiwShsIsEobCLBKE++1l5Pd1F6WmqZ1b5/8/sKfm95gMzS9z68Yo/XfK5UxuTtV8d8pexLuWtBL083asGgNJUzgNMO/WS/7qVzvOn305c5m91fXRj+vqDk5f6fXLr8eu9w/7U4WV7l7n1/mMnk7XK0ZwlH53XjTPqs4uEp7CLBKGwiwShsIsEobCLBKGwiwShsIsEoT77WTnL87In3VftHPf76KPH/aWk35hc49YX5cx3/3C69mWPR6/2+8nTi3Pm6o/6y2ib87JOLvOvbTi50e/hX3jREbd+1eJ0v3qgZ8w9dtr8LZl/c+hit36stMKtL3/V+Zk4fsI9ttY1AnRmFwlCYRcJQmEXCUJhFwlCYRcJQmEXCUJhFwlCffZqzcwkS13+EuGonPZf5mMzfh++0lH7/5PXLj7u1ld84bT/AF/wy8u6x/3H70m/OKu6/V73Zb3D/pPnmHbW2z9eXugem/c9MfOvEejwlyAAz6TvUHF+1mbvkO6zm9ODz/0pIrmO5HMk95B8g+S3s9v7ST5Lcm/2cXneY4lIcao5ZcwAuNfMrgRwHYC7SW4EcB+A7Wa2AcD27GsRaVO5YTezYTN7Jft8DMAeAGsA3AZgW3a3bQBub9YgRaR+n+iPQZIXAbgGwEsABsxsGJj9HwKAVYljtpAcIjk0jZw9rESkaaoOO8k+AI8B+I6ZpVfLO4eZbTWzQTMb7EJ6AUARaa6qwk6yC7NBf8TMfpHdfJjk6qy+GsBIc4YoIo2Q23ojSQAPAdhjZj+YU3oSwJ0AHsg+PtGUEbaK+VM9y8fSLawVv/VbRL3H5/0L5w8eshvc+sp1x9z6ioXp9tmSbr8HdMN5e936hp4P3PpFnf7YPGMVfznmkfJit/7iqUvd+r7TK5O1vUfTNQAYO5XeohsA+l7062uG/JZm5Uh6G2+bzmm9eZzWWzV99usBfBPALpI7s9u+i9mQ/5zkXQDeA/D12kcoIs2WG3YzewFA6gqCmxo7HBFpFl0uKxKEwi4ShMIuEoTCLhKEwi4ShKa4npWzPK9NTSVrlUN+L7pv3O91r+280K0f3ej3hI9ckN4eeOGKM+6xS7v8Kaq99JdznsjplY9VepO1357Y4B773O/8eu9r/jTVhYfT39OlR/xe9opTfr17/wG3Xhn1pxZXxp3XPW+p6JztxVN0ZhcJQmEXCUJhFwlCYRcJQmEXCUJhFwlCYRcJgt7Ss422hP32RQacKJfTF2W336su9eSs8NPdlX7srnQNAKzP71XbAn9seThdTteO+QseVU771wjYRHHLnFk5/d81ewd/fYRat13O85Jtx0kbnfcHTmd2kSAUdpEgFHaRIBR2kSAUdpEgFHaRIBR2kSA0n70V8ubKT/r94nJOXaQaOrOLBKGwiwShsIsEobCLBKGwiwShsIsEobCLBJEbdpLrSD5Hcg/JN0h+O7v9fpLvk9yZ/bu1+cMVkVpVc1HNDIB7zewVkosB7CD5bFb7oZn9c/OGJyKNUs3+7MMAhrPPx0juAbCm2QMTkcb6RH+zk7wIwDUAXspuuofk6yQfJrk8ccwWkkMkh6ahyz5FilJ12En2AXgMwHfM7CSABwFcAmATZs/835/vODPbamaDZjbYhZy11ESkaaoKO8kuzAb9ETP7BQCY2WEzK5tZBcCPAVzbvGGKSL2qeTeeAB4CsMfMfjDn9tVz7nYHgN2NH56INEo178ZfD+CbAHaR3Jnd9l0Am0luAmAA9gP4VlNGKCIf5S1N7symrubd+BcAzPfoT+WPSkTaha6gEwlCYRcJQmEXCUJhFwlCYRcJQmEXCaKlS0mzVEJpQXqL4Mr4uP8ALdxeWqQwOVt8lxYsSB86nj5/68wuEoTCLhKEwi4ShMIuEoTCLhKEwi4ShMIuEgSthb1rkkcA/H7OTSsAfNiyAXwy7Tq2dh0XoLHVqpFju9DMVs5XaGnYP/bk5JCZDRY2AEe7jq1dxwVobLVq1dj0a7xIEAq7SBBFh31rwc/vadexteu4AI2tVi0ZW6F/s4tI6xR9ZheRFlHYRYIoJOwkbyH5Fsl9JO8rYgwpJPeT3JVtQz1U8FgeJjlCcvec2/pJPktyb/Zx3j32ChpbW2zj7WwzXuhrV/T25y3/m51kB4C3AXwZwEEALwPYbGZvtnQgCST3Axg0s8IvwCB5A4BTAP7dzD6f3fZPAEbN7IHsf5TLzezv2mRs9wM4VfQ23tluRavnbjMO4HYAf4sCXztnXH+DFrxuRZzZrwWwz8zeMbMpAD8DcFsB42h7ZvY8gNFzbr4NwLbs822Y/WFpucTY2oKZDZvZK9nnYwDObjNe6GvnjKsligj7GgAH5nx9EO2137sB+CXJHSS3FD2YeQyY2TAw+8MDYFXB4zlX7jberXTONuNt89rVsv15vYoI+3wLbLVT/+96M/tjAF8FcHf266pUp6ptvFtlnm3G20Kt25/Xq4iwHwSwbs7XawEcKmAc8zKzQ9nHEQCPo/22oj58dgfd7ONIweP5g3baxnu+bcbRBq9dkdufFxH2lwFsILmeZDeAbwB4soBxfAzJRdkbJyC5CMBX0H5bUT8J4M7s8zsBPFHgWD6iXbbxTm0zjoJfu8K3Pzezlv8DcCtm35H/HYC/L2IMiXFdDOC17N8bRY8NwKOY/bVuGrO/Ed0F4DwA2wHszT72t9HY/gPALgCvYzZYqwsa259h9k/D1wHszP7dWvRr54yrJa+bLpcVCUJX0IkEobCLBKGwiwShsIsEobCLBKGwiwShsIsE8f+y7G4RnpmpYQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(result.reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
